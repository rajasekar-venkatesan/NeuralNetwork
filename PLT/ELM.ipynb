{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import pinv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: iris.csv\n",
      "150 samples loaded with 4 features\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "fname = 'iris.csv'\n",
    "print('Loading data from file: {}'.format(fname))\n",
    "data = pd.read_csv(fname).values\n",
    "# print(data[:5])\n",
    "np.random.shuffle(data)\n",
    "print('{} samples loaded with {} features'.format(data.shape[0], data.shape[1]-1))\n",
    "# print(data[:5])\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are: {'virginica', 'setosa', 'versicolor'}\n",
      "Labels to index map: {'virginica': 0, 'setosa': 1, 'versicolor': 2}\n"
     ]
    }
   ],
   "source": [
    "#Split Labels and Features\n",
    "feats = data[:,:-1]\n",
    "labels_raw = data[:, -1]\n",
    "# print(feats[:5])\n",
    "# print(labels[:5])\n",
    "labels_set = set(labels_raw)\n",
    "print('Labels are: {}'.format(labels_set))\n",
    "labels2index_map = {label: ind for ind, label in enumerate(labels_set)}\n",
    "print('Labels to index map: {}'.format(labels2index_map))\n",
    "labels = np.array([labels2index_map[label] for label in labels_raw])\n",
    "# print(labels[:5])\n",
    "# print(labels_raw[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.6 2.9 4.6 1.3]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.0 2.9 4.5 1.5]]\n",
      "Scaling Features Done\n",
      "[[0.63888889 0.375      0.61016949 0.5       ]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333]\n",
      " [0.33333333 0.25       0.57627119 0.45833333]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.47222222 0.375      0.59322034 0.58333333]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajasekar/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Scaling\n",
    "print(feats[:5])\n",
    "scaler = MinMaxScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "print('Scaling Features Done')\n",
    "print(feats[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into training and testing set\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(feats, labels, test_size=0.2, random_state=42)\n",
    "print('Divided into training and testing set')\n",
    "# print(train_X[:5])\n",
    "# print(train_y[:5])\n",
    "# print(test_X[:5])\n",
    "# print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels to bipolar\n"
     ]
    }
   ],
   "source": [
    "#To Bipolar\n",
    "def to_bipolar(y, labels2index_map):\n",
    "    y_bipolar = np.ones((len(y), len(labels2index_map))) * -1\n",
    "    for i, label in enumerate(y):\n",
    "        y_bipolar[i, label] = 1\n",
    "    return y_bipolar\n",
    "train_y_bipolar = to_bipolar(train_y, labels2index_map)\n",
    "test_y_bipolar = to_bipolar(test_y, labels2index_map)\n",
    "# print(train_y[:5])\n",
    "# print(to_bipolar(train_y[:5], labels2index_map))\n",
    "print('Converted labels to bipolar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid\n",
    "def sigmoid(data):\n",
    "    result = 1 / (1 + np.exp(-1 * data))\n",
    "    return result\n",
    "# print(sigmoid(np.array([-1, 0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Batch ELM\n",
    "nHidden = 10\n",
    "\n",
    "input_dim = train_X.shape[1]\n",
    "hidden_dim = nHidden\n",
    "output_dim = train_y_bipolar.shape[1]\n",
    "\n",
    "i2h = np.random.uniform(-1,1,(input_dim, hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  91.12603529   21.3422548  -111.8557072 ]\n",
      " [-177.28266371  452.54893475 -278.93034761]\n",
      " [  24.03478466 -205.27133861  182.38275925]\n",
      " [   6.76470279   81.70403368  -88.74056053]\n",
      " [ 293.06916878  -15.75988761 -276.54524593]]\n",
      "[[ 1.67832788 -1.04150422 -1.6367777 ]\n",
      " [-0.73239455 -0.899748    0.63218459]\n",
      " [-0.50401053 -0.84404674  0.34886642]\n",
      " [-0.85459467  0.93320433 -1.07835141]\n",
      " [-0.55472898 -0.77679943  0.33195204]]\n",
      "[0 2 2 1 2 2 1 2 0 0 1 2 1 0 1 2 2 0 2 2 1 1 1 1 2 1 1 2 1 1]\n",
      "[0 2 2 1 2 2 1 2 0 0 1 2 1 0 1 2 2 0 2 2 1 1 1 1 2 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "#ELM Train\n",
    "H = sigmoid(np.dot(train_X, i2h))\n",
    "h2o = np.dot(pinv(H), train_y_bipolar)\n",
    "print(h2o[:5])\n",
    "\n",
    "#ELM Predict\n",
    "H = sigmoid(np.dot(test_X, i2h))\n",
    "y_pred = np.dot(H, h2o)\n",
    "print(y_pred[:5])\n",
    "y_pred = np.array([np.argmax(y_pred[i,:]) for i in range(len(y_pred))])\n",
    "print(y_pred)\n",
    "print((test_y))#>0)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         5\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred))\n",
    "print(accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
